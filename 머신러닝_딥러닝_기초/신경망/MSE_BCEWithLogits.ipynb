{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLbvkYes3XIHYi5GPsQ6ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junsu122/AI_Basic/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88/%EC%8B%A0%EA%B2%BD%EB%A7%9D/MSE_BCEWithLogits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. 공통 신경망 구조 (BatchNorm 포함)\n",
        "class ComparisonNet(nn.Module):\n",
        "    def __init__(self, output_size):\n",
        "        super(ComparisonNet, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(10, 20),\n",
        "            nn.BatchNorm1d(20),  # [개념: BatchNorm] 데이터 분포 정규화\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "# 가상 데이터 생성 (100개의 샘플, 10개의 특징)\n",
        "inputs = torch.randn(100, 10)\n",
        "# 회귀용 정답 (연속적인 숫자) / 분류용 정답 (0 또는 1)\n",
        "target_reg = torch.randn(100, 1)\n",
        "target_bin = torch.randint(0, 2, (100, 1)).float()\n",
        "\n",
        "# 2. 모델 및 손실 함수 설정\n",
        "model_reg = ComparisonNet(output_size=1)\n",
        "model_bin = ComparisonNet(output_size=1)\n",
        "\n",
        "criterion_mse = nn.MSELoss()            # [개념: MSE] 회귀용 오차 계산\n",
        "criterion_bce = nn.BCEWithLogitsLoss()  # [개념: BCEWithLogits] 이진 분류용 (Sigmoid 포함)\n",
        "\n",
        "# 3. 최적화 도구 (경사하강법 기반 Adam)\n",
        "optimizer_reg = optim.Adam(model_reg.parameters(), lr=0.01)\n",
        "optimizer_bin = optim.Adam(model_bin.parameters(), lr=0.01)\n",
        "\n",
        "# 4. 학습 및 오차 비교\n",
        "print(f\"{'Epoch':<8} | {'Regression (MSE)':<20} | {'Binary (BCEWithLogits)':<20}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for epoch in range(101):\n",
        "    # --- Regression 학습 ---\n",
        "    optimizer_reg.zero_grad()\n",
        "    out_reg = model_reg(inputs)\n",
        "    loss_reg = criterion_mse(out_reg, target_reg) # 오차 구하기\n",
        "    loss_reg.backward()                           # 역전파\n",
        "    optimizer_reg.step()                          # 경사하강법 업데이트\n",
        "\n",
        "    # --- Binary Classification 학습 ---\n",
        "    optimizer_bin.zero_grad()\n",
        "    out_bin = model_bin(inputs)\n",
        "    loss_bin = criterion_bce(out_bin, target_bin) # 오차 구하기\n",
        "    loss_bin.backward()                           # 역전파\n",
        "    optimizer_bin.step()                          # 경사하강법 업데이트\n",
        "\n",
        "    if epoch % 20 == 0:\n",
        "        print(f\"{epoch:<8} | {loss_reg.item():<20.4f} | {loss_bin.item():<20.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FNq1BtkFBAt",
        "outputId": "652825c9-90ae-48bb-b5e4-5e931321df39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    | Regression (MSE)     | Binary (BCEWithLogits)\n",
            "------------------------------------------------------------\n",
            "0        | 1.1476               | 0.7397              \n",
            "20       | 0.6271               | 0.6008              \n",
            "40       | 0.3648               | 0.4989              \n",
            "60       | 0.2096               | 0.3931              \n",
            "80       | 0.1094               | 0.2998              \n",
            "100      | 0.0446               | 0.2142              \n"
          ]
        }
      ]
    }
  ]
}