# 📉 선형 회귀와 최적화 알고리즘

데이터의 흐름을 이해하고 가장 적합한 모델을 찾아가는 머신러닝의 기초 과정을 정리합니다.

---

### 1️⃣ 선형 회귀 (Linear Regression)
**"데이터를 가장 잘 대변하는 하나의 선을 긋는 것"**
데이터들의 분포를 가장 잘 나타내는 **직선($y = wx + b$)**을 찾아내는 과정입니다.

* **Goal:** 실제값과 모델이 예측한 값의 차이(오차)를 최소화하는 최적의 **$w$ (가중치)**와 **$b$ (편향)**를 찾는 것입니다.
* **Visual:** 무질서한 점들 사이를 관통하는 가장 깔끔한 직선을 상상해 보세요.



---

### 2️⃣ 손실 함수 (Loss Function)
**"모델이 얼마나 틀렸는지 알려주는 나침반"**
학습 과정에서 현재 모델이 정답과 얼마나 거리가 먼지 수치화하는 지표입니다.

* **MSE (Mean Squared Error):** 선형 회귀에서 주로 사용하며, 오차를 제곱하여 평균을 낸 값입니다.
* **특징:** 오차가 클수록 제곱에 의해 값이 훨씬 커지므로, 틀린 정도를 더 민감하게 반영합니다.

$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

---

### 3️⃣ 경사하강법 (Gradient Descent)
**"최적의 값을 찾아 내려가는 골짜기 여행"**
손실 함수의 값이 가장 작은 지점(최솟값)을 찾기 위해 반복적으로 파라미터를 업데이트하는 알고리즘입니다.

* **🔍 미분 (Gradient):** 현재 위치에서 손실 함숫값이 작아지는 방향(기울기)을 찾습니다.
* **🏃 업데이트:** 찾은 방향으로 **학습률(Learning Rate)**만큼 조금씩 이동합니다.
* **🏁 목표:** 기울기가 0에 가까워지는 '바닥'에 도달할 때까지 반복하여 최적의 $w$와 $b$를 결정합니다.



---

### 💡 핵심 요약 (Key Takeaway)

| 단계 | 용어 | 쉬운 설명 | 역할 |
| :--- | :--- | :--- | :--- |
| **1단계** | **선형 회귀** | 선 긋기 | 모델 정의 |
| **2단계** | **손실 함수** | 점수 매기기 | 모델 평가 |
| **3단계** | **경사하강법** | 길 찾기 | 모델 최적화 |

---
