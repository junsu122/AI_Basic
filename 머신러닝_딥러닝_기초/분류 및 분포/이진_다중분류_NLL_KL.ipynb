{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5VMa5kIQWcK/NM08mFMc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junsu122/AI_Basic/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88/%EB%B6%84%EB%A5%98%20%EB%B0%8F%20%EB%B6%84%ED%8F%AC/%EC%9D%B4%EC%A7%84_%EB%8B%A4%EC%A4%91%EB%B6%84%EB%A5%98_NLL_KL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_tensor = torch.FloatTensor(X_scaled)\n",
        "\n",
        "# 2. ëª¨ë¸ ì •ì˜ (ì¶œë ¥ ë…¸ë“œ ìˆ˜ë¥¼ ì¸ìë¡œ ë°›ìŒ)\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# 3. ì„±ëŠ¥ ë¹„êµ í•¨ìˆ˜ (ì´ì§„/ë‹¤ì¤‘ í†µí•©)\n",
        "def compare_losses(num_classes, mode_name):\n",
        "    # ë°ì´í„° ì¤€ë¹„ (ì´ì§„ ë¶„ë¥˜ë©´ 0, 1ë²ˆ í´ë˜ìŠ¤ë§Œ ì¶”ì¶œ)\n",
        "    if num_classes == 2:\n",
        "        mask = y < 2\n",
        "        curr_X, curr_y = X_tensor[mask], torch.LongTensor(y[mask])\n",
        "    else:\n",
        "        curr_X, curr_y = X_tensor, torch.LongTensor(y)\n",
        "\n",
        "    # KLDivìš© ì •ë‹µ ë¶„í¬ (One-hot)\n",
        "    y_dist = F.one_hot(curr_y, num_classes=num_classes).float()\n",
        "\n",
        "    # ë‘ ëª¨ë¸ ìƒì„±\n",
        "    model_nll = IrisNet(num_classes)\n",
        "    model_kl = IrisNet(num_classes)\n",
        "\n",
        "    opt_nll = optim.Adam(model_nll.parameters(), lr=0.01)\n",
        "    opt_kl = optim.Adam(model_kl.parameters(), lr=0.01)\n",
        "\n",
        "    # í•™ìŠµ\n",
        "    for epoch in range(100):\n",
        "        # NLLLoss í•™ìŠµ\n",
        "        opt_nll.zero_grad()\n",
        "        out_nll = F.log_softmax(model_nll(curr_X), dim=1)\n",
        "        loss_nll = nn.NLLLoss()(out_nll, curr_y)\n",
        "        loss_nll.backward()\n",
        "        opt_nll.step()\n",
        "\n",
        "        # KLDiv í•™ìŠµ\n",
        "        opt_kl.zero_grad()\n",
        "        out_kl = F.log_softmax(model_kl(curr_X), dim=1)\n",
        "        loss_kl = nn.KLDivLoss(reduction='batchmean')(out_kl, y_dist)\n",
        "        loss_kl.backward()\n",
        "        opt_kl.step()\n",
        "\n",
        "    # ê²°ê³¼ ë¶„ì„ ì¶œë ¥\n",
        "    print(f\"\\nğŸš€ [{mode_name}] ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ\")\n",
        "    print(f\"{'Metric':<15} | {'NLLLoss Model':<15} | {'KLDiv Model':<15}\")\n",
        "    print(\"-\" * 55)\n",
        "\n",
        "    # ìƒ˜í”Œ ê²°ê³¼ (ì²« ë²ˆì§¸ ë°ì´í„° í™•ì¸)\n",
        "    with torch.no_grad():\n",
        "        prob_nll = F.softmax(model_nll(curr_X[0:1]), dim=1)\n",
        "        prob_kl = F.softmax(model_kl(curr_X[0:1]), dim=1)\n",
        "\n",
        "    print(f\"{'Final Loss':<15} | {loss_nll.item():<15.4f} | {loss_kl.item():<15.4f}\")\n",
        "    print(f\"{'ì •ë‹µ í™•ì‹ ë„(%)':<15} | {prob_nll[0][curr_y[0]].item()*100:<15.2f} | {prob_kl[0][curr_y[0]].item()*100:<15.2f}\")\n",
        "\n",
        "# 4. ì‹¤í–‰\n",
        "compare_losses(num_classes=2, mode_name=\"ì´ì§„ ë¶„ë¥˜ (Setosa vs Versicolor)\")\n",
        "compare_losses(num_classes=3, mode_name=\"ë‹¤ì¤‘ ë¶„ë¥˜ (All 3 Classes)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmG7l9c_SPzs",
        "outputId": "9e548985-2337-492e-9f7a-cba1151da2db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ [ì´ì§„ ë¶„ë¥˜ (Setosa vs Versicolor)] ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ\n",
            "Metric          | NLLLoss Model   | KLDiv Model    \n",
            "-------------------------------------------------------\n",
            "Final Loss      | 0.0022          | 0.0021         \n",
            "ì •ë‹µ í™•ì‹ ë„(%)       | 99.89           | 99.97          \n",
            "\n",
            "ğŸš€ [ë‹¤ì¤‘ ë¶„ë¥˜ (All 3 Classes)] ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ\n",
            "Metric          | NLLLoss Model   | KLDiv Model    \n",
            "-------------------------------------------------------\n",
            "Final Loss      | 0.0653          | 0.0842         \n",
            "ì •ë‹µ í™•ì‹ ë„(%)       | 99.79           | 99.91          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. ë°ì´í„° ì¤€ë¹„ (ë¶“ê½ƒ ë°ì´í„°)\n",
        "iris = load_iris()\n",
        "X = StandardScaler().fit_transform(iris.data)\n",
        "X_tensor = torch.FloatTensor(X)\n",
        "\n",
        "# 2. ì´ì§„ ë¶„ë¥˜ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ (Setosa vs Versicolor)\n",
        "# ì¶œë ¥ ë…¸ë“œê°€ 2ê°œì¸ ê²½ìš°\n",
        "logits_binary = torch.tensor([[2.5, -1.2]]) # ëª¨ë¸ì´ ë‚´ë±‰ì€ ì›ì‹œ ì ìˆ˜(Logits)\n",
        "probs_binary = F.softmax(logits_binary, dim=1) # í™•ë¥ ë¡œ ë³€í™˜\n",
        "\n",
        "print(\"--- [1] ì´ì§„ ë¶„ë¥˜ ì˜ˆì¸¡ (Binary Classification) ---\")\n",
        "print(f\"ì›ì‹œ ì ìˆ˜(Logits): {logits_binary.numpy()}\")\n",
        "print(f\"ë³€í™˜ëœ í™•ë¥ : {probs_binary.numpy()}\")\n",
        "print(f\"í•´ì„: 0ë²ˆ í´ë˜ìŠ¤ì¼ í™•ë¥  {probs_binary[0][0]*100:.2f}%, 1ë²ˆ í´ë˜ìŠ¤ì¼ í™•ë¥  {probs_binary[0][1]*100:.2f}%\")\n",
        "print(f\"ìµœì¢… ê²°ì •: {torch.argmax(probs_binary).item()}ë²ˆ í’ˆì¢…\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# 3. ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜ (Setosa, Versicolor, Virginica)\n",
        "# ì¶œë ¥ ë…¸ë“œê°€ 3ê°œì¸ ê²½ìš°\n",
        "logits_multi = torch.tensor([[1.1, 3.8, -0.5]]) # ëª¨ë¸ì´ ë‚´ë±‰ì€ ì›ì‹œ ì ìˆ˜(Logits)\n",
        "probs_multi = F.softmax(logits_multi, dim=1) # í™•ë¥ ë¡œ ë³€í™˜\n",
        "\n",
        "print(\"--- [2] ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì¸¡ (Multi-class Classification) ---\")\n",
        "print(f\"ì›ì‹œ ì ìˆ˜(Logits): {logits_multi.numpy()}\")\n",
        "print(f\"ë³€í™˜ëœ í™•ë¥ : {probs_multi.numpy()}\")\n",
        "for i, p in enumerate(probs_multi[0]):\n",
        "    print(f\"{iris.target_names[i]}: {p*100:.2f}%\")\n",
        "print(f\"ìµœì¢… ê²°ì •: {iris.target_names[torch.argmax(probs_multi).item()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGnRHDUtStn5",
        "outputId": "8ef8c3e4-f234-4962-ef9a-3f5bfecb54e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- [1] ì´ì§„ ë¶„ë¥˜ ì˜ˆì¸¡ (Binary Classification) ---\n",
            "ì›ì‹œ ì ìˆ˜(Logits): [[ 2.5 -1.2]]\n",
            "ë³€í™˜ëœ í™•ë¥ : [[0.975873   0.02412702]]\n",
            "í•´ì„: 0ë²ˆ í´ë˜ìŠ¤ì¼ í™•ë¥  97.59%, 1ë²ˆ í´ë˜ìŠ¤ì¼ í™•ë¥  2.41%\n",
            "ìµœì¢… ê²°ì •: 0ë²ˆ í’ˆì¢…\n",
            "\n",
            "==================================================\n",
            "\n",
            "--- [2] ë‹¤ì¤‘ ë¶„ë¥˜ ì˜ˆì¸¡ (Multi-class Classification) ---\n",
            "ì›ì‹œ ì ìˆ˜(Logits): [[ 1.1  3.8 -0.5]]\n",
            "ë³€í™˜ëœ í™•ë¥ : [[0.06218277 0.92526275 0.01255448]]\n",
            "setosa: 6.22%\n",
            "versicolor: 92.53%\n",
            "virginica: 1.26%\n",
            "ìµœì¢… ê²°ì •: versicolor\n"
          ]
        }
      ]
    }
  ]
}